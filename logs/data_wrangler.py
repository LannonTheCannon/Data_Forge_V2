# Disclaimer: This function was generated by AI. Please review before using.
# Agent Name: data_wrangling_agent
# Time Created: 2025-04-27 17:03:54

def data_wrangler(data_list):
    import pandas as pd
    import numpy as np
    '''
    Wrangle the data provided in data_list to compare average salary_in_usd trends over work_year
    for selected job titles within the highest-paying employee_residence countries.
    
    data_list: A list of one or more pandas data frames containing the raw data to be wrangled.
    
    Returns:
        A pandas DataFrame aggregated by work_year, employee_residence, and job_title showing the 
        average salary_in_usd to analyze temporal salary shifts regionally.
    '''


    # Ensure data_list is a list even if a single dataframe is provided
    if not isinstance(data_list, list):
        data_list = [data_list]
    
    # For this task, we expect a single DataFrame named 'main' based on the prompt,
    # but if more datasets were provided, merging logic would go here.
    # Since only one dataset is provided, we assign it directly.
    df = data_list[0].copy()
    
    # Step 1: Identify highest-paying employee_residence countries
    # Group by employee_residence and compute average salary_in_usd
    avg_salary_by_country = df.groupby('employee_residence')['salary_in_usd'].mean().reset_index()
    
    # Sort descending by average salary to find top countries
    avg_salary_by_country = avg_salary_by_country.sort_values(by='salary_in_usd', ascending=False)
    
    # Decide on a threshold or top N countries to focus on
    # Here, we select top 5 highest-paying countries for meaningful regional comparison
    top_n = 5
    top_countries = avg_salary_by_country.head(top_n)['employee_residence'].tolist()
    
    # Step 2: Filter dataset to include only rows where employee_residence is in top_countries
    df_filtered = df[df['employee_residence'].isin(top_countries)].copy()
    
    # Step 3: Select job titles of interest
    # We identify top 5 job titles by frequency within the filtered dataset for comparison
    top_job_titles = (
        df_filtered['job_title']
        .value_counts()
        .head(5)
        .index
        .tolist()
    )
    
    # Step 4: Filter dataset further for selected job titles
    df_filtered = df_filtered[df_filtered['job_title'].isin(top_job_titles)].copy()
    
    # Step 5: Aggregate data to compute average salary_in_usd grouped by work_year, employee_residence, job_title
    df_grouped = (
        df_filtered
        .groupby(['work_year', 'employee_residence', 'job_title'], as_index=False)['salary_in_usd']
        .mean()
        .rename(columns={'salary_in_usd': 'avg_salary_in_usd'})
    )
    
    # Step 6 (Optional): Pivot the data for easier trend analysis
    # As user wants the data frame, we will keep it long-form (not pivoted),
    # but comment how to pivot if needed.
    # Example pivot (commented out):
    # df_pivot = df_grouped.pivot_table(
    #     index=['work_year', 'employee_residence'],
    #     columns='job_title',
    #     values='avg_salary_in_usd'
    # ).reset_index()
    
    # Step 7: Ensure data types appropriate for time series analysis
    # Convert work_year to int (should already be int), just enforce type and sort
    df_grouped['work_year'] = df_grouped['work_year'].astype(int)
    df_grouped = df_grouped.sort_values(by=['employee_residence', 'job_title', 'work_year'])
    
    # Step 8: Check for and handle any missing or outlier salary data
    # Missing avg_salary_in_usd is unlikely after groupby mean, but check and drop if any
    df_grouped = df_grouped.dropna(subset=['avg_salary_in_usd'])
    
    # Handle outliers: remove extreme salaries outside 1st and 99th percentile within each job_title and country
    def remove_outliers(group):
        lower = group['avg_salary_in_usd'].quantile(0.01)
        upper = group['avg_salary_in_usd'].quantile(0.99)
        return group[(group['avg_salary_in_usd'] >= lower) & (group['avg_salary_in_usd'] <= upper)]
    
    df_grouped = df_grouped.groupby(['employee_residence', 'job_title']).apply(remove_outliers).reset_index(drop=True)
    
    # Final data ready for temporal salary trend analysis regionally by job title within highest-paying countries
    return df_grouped